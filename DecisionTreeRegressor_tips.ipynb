{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTreeRegressor_tips",
      "provenance": [],
      "authorship_tag": "ABX9TyPL6CUL8Evi3DoyTJq34H9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSpanias/ml_training/blob/master/DecisionTreeRegressor_tips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree Regressor Algorithm**\n",
        "\n",
        "*This notebook was developed for Decision Tree practice and the resulting code is a blend of various different resources.*\n",
        "\n",
        "Based mostly on:\n",
        "* [Machine Learning for Absolute Beginners](https://scatterplotpress.teachable.com/courses)\n",
        "\n",
        "Modified based on:\n",
        "*  [\n",
        "*  [\n",
        "*  [\n",
        "\n"
      ],
      "metadata": {
        "id": "2R80N-hgzsRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [Data Cleaning](#DataCleaning)\n",
        "2. [KFold Cross-Validation with different criterion (gini, entropy)](#KFold)\n",
        "3. [Decision Tree Visualization (GraphViz)](#GraphViz)\n",
        "4. [Pruning the Decision Tree](#Pruning)\n",
        "  * [Pre-Pruning](#Pre-Pruning)\n",
        "  * [Post-Pruning](#Post-Pruning)\n",
        "5. [Conclusions](#Conclusions)\n"
      ],
      "metadata": {
        "id": "7ZMchYjjJ4MK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "p1AnphzkfQEF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\")"
      ],
      "metadata": {
        "id": "ODSwg_J6gAzx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 5 rows of data\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3XLfSDyngMtQ",
        "outputId": "10a9b4de-b038-4237-9086-823b4147a7d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_bill</th>\n",
              "      <th>tip</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoker</th>\n",
              "      <th>day</th>\n",
              "      <th>time</th>\n",
              "      <th>size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.99</td>\n",
              "      <td>1.01</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>Sun</td>\n",
              "      <td>Dinner</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.34</td>\n",
              "      <td>1.66</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Sun</td>\n",
              "      <td>Dinner</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21.01</td>\n",
              "      <td>3.50</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Sun</td>\n",
              "      <td>Dinner</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.68</td>\n",
              "      <td>3.31</td>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>Sun</td>\n",
              "      <td>Dinner</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24.59</td>\n",
              "      <td>3.61</td>\n",
              "      <td>Female</td>\n",
              "      <td>No</td>\n",
              "      <td>Sun</td>\n",
              "      <td>Dinner</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   total_bill   tip     sex smoker  day    time  size\n",
              "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
              "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
              "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
              "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
              "4       24.59  3.61  Female     No  Sun  Dinner     4"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print info about the dataset\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9krWufeOgtDM",
        "outputId": "94961636-ce29-4c56-f3f1-135c4449711e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 244 entries, 0 to 243\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   total_bill  244 non-null    float64\n",
            " 1   tip         244 non-null    float64\n",
            " 2   sex         244 non-null    object \n",
            " 3   smoker      244 non-null    object \n",
            " 4   day         244 non-null    object \n",
            " 5   time        244 non-null    object \n",
            " 6   size        244 non-null    int64  \n",
            "dtypes: float64(2), int64(1), object(4)\n",
            "memory usage: 13.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"DataCleaning\"> </a>\n",
        "# **Data Cleaning**\n",
        "\n",
        "* Missing values\n",
        "* Duplicate rows"
      ],
      "metadata": {
        "id": "bmQHEim3pf-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG_rrP8bgyWI",
        "outputId": "d602ae94-9e67-43be-a176-b39f3e8876b7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "total_bill    0\n",
              "tip           0\n",
              "sex           0\n",
              "smoker        0\n",
              "day           0\n",
              "time          0\n",
              "size          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicates\n",
        "print(df.duplicated().sum())\n",
        "# remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIbPORgSg4XW",
        "outputId": "f0f241bb-1e67-49aa-ce06-c2ebe3d9284f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data PreProcessing**"
      ],
      "metadata": {
        "id": "s7iGYgd0dfW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete smoker variable\n",
        "del df['smoker']"
      ],
      "metadata": {
        "id": "izMBTR0yf67y"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert non-numerical data to boolean using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['time', 'day', 'sex'])"
      ],
      "metadata": {
        "id": "WgGrgZSPdi2V"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='KFold'> </a>\n",
        " # **KFold Cross Validation with different criterion** \n",
        "(squared_error, friedman_mse, absolute_error, poisson)"
      ],
      "metadata": {
        "id": "mMNKKIBJSh7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the required libraries & methods."
      ],
      "metadata": {
        "id": "cUa2xkxUT6GP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4HcF3cepeIRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # convert DataFrame to arrays, calculate means\n",
        "from sklearn.tree import DecisionTreeRegressor # algorithm required\n",
        "from sklearn.model_selection import train_test_split # split data\n",
        "from sklearn.model_selection import KFold # perform a KFold Cross-Validation\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score # evaluation metrics"
      ],
      "metadata": {
        "id": "vPpSDFOwR6iM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Assign Xs (features) & y (target) \n",
        "2. Convert them from pandas DataFrame (matrix) and pandas Series (single column) to ***numpy 2- and 1-Dimensional numpy arrays***, respectively.\n",
        "\n",
        "  Pandas DataFrames & Series are easier to read by a human, but numpy's arrays are ***easier to handled by the computer***.  "
      ],
      "metadata": {
        "id": "sJTTeGeuT3tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from df drop the specified variable, axis=1: drop the whole column\n",
        "X = df.drop(columns='tip', axis=1)\n",
        "# convert pandas dataframe to a 2-Dimensional numpy array\n",
        "#X = X.values\n",
        "# confirm that X's shape is 2D\n",
        "print(X.shape)\n",
        "\n",
        "# assing target\n",
        "y = df['tip']\n",
        "# convert pandas series to a 1-Dimensional numpy array\n",
        "#y = y.values\n",
        "# confirm that y's shape is 1D\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIS7ZPWPhDuf",
        "outputId": "67a36d8b-0ce9-495b-dac6-074475a121ec"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(243, 10)\n",
            "(243,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform KFold Cross-Validation to compare the mean accuracy of:\n",
        "1. A Decision Tree model with gini as the criterion.\n",
        "2. A Decision Tree model with entropy as the criterion."
      ],
      "metadata": {
        "id": "Beh6FeU0ZQDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the number of splits (train/test sets) and shuffle rows\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# we want to cross-validate the model with both gini and entropy\n",
        "for criterion in ['squared_error', 'friedman_mse', 'absolute_error',\n",
        "                  'poisson']:\n",
        "  # {} = placeholders, .format(x) = put x in the placeholders\n",
        "  print(\"Decision Tree - {}\" .format(criterion))\n",
        "  # create an empty list of each metric so we can later \n",
        "  # store the score in it for each of the 5 splits\n",
        "  mae = []\n",
        "\n",
        "  # each split of X produces a training and testing set\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # select algorithm with the specified criterion\n",
        "    model = DecisionTreeRegressor(criterion=criterion)\n",
        "    # train the model using training data\n",
        "    model.fit(X_train, y_train)\n",
        "    # predict using the testing data\n",
        "    y_pred = model.predict(X_test)\n",
        "    # calculate and append accuracy score at the end of each list\n",
        "    mae.append(mean_absolute_error(y_test, y_pred))\n",
        "    \n",
        "  # print a message while calculating the mean score of each metric\n",
        "  # {:.4f} = format x to 4 decimal places, .format(x) = put x into the placeholder\n",
        "    print(\"Mean Absolute Error: {:.4f}\" .format(np.mean(mae)))"
      ],
      "metadata": {
        "id": "Asq1cbtj7xc6",
        "outputId": "a08bfeb0-20a1-4153-e7ff-129139421f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - squared_error\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-c3a8369d7db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# each split of X produces a training and testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# select algorithm with the specified criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([  0,   2,   3,   4,   6,   7,   8,   9,  10,  11,\\n            ...\\n            231, 232, 233, 236, 237, 238, 239, 240, 241, 242],\\n           dtype='int64', length=194)] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entropy seems to work better, hence, we will train our model using entropy as the criterion."
      ],
      "metadata": {
        "id": "IcFks7nTZwlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select algorith and set entropy as the criterion\n",
        "model = DecisionTreeRegressor()\n",
        "# split training and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=33)\n",
        "# train the model using training data\n",
        "model.fit(X_train, y_train)\n",
        "# predict using the test data\n",
        "y_pred_GS = model.predict(X_test)\n",
        "# print MAE, {} = placeholder, .format(x) = put x into the placeholder\n",
        "print(\"Mean Absolute Error: {:.2f}\" .format(mean_absolute_error(y_test, y_pred_GS)))"
      ],
      "metadata": {
        "id": "sK_shfRaGra7",
        "outputId": "068b5b2e-e307-42fa-be6b-1d77920acd84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 1.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='GraphViz'> </a>\n",
        "# **Decision Tree Visualization** (GraphViz)\n",
        "\n",
        "Decision Trees benefits:\n",
        "1. **Interpretability**: clarity of information representation, useful for explaining the prediction to a non-technical audience.\n",
        "2. **Transparency**: can greatly help in the *decision making process*. \n",
        "\n",
        "*If you're going to run this on your computer, make sure to install graphviz first. You can do this by opening your command prompt and typing \"**pip install graphviz**\".*"
      ],
      "metadata": {
        "id": "pjL5g_fQJjb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample Visualization for easier interpretation of the process:"
      ],
      "metadata": {
        "id": "uQJTC9wvdc5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a list with the feature names\n",
        "feature_names= ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree',\n",
        "        'age']\n",
        "\n",
        "# assign X and y variables\n",
        "X = df[feature_names].values\n",
        "y = df['label'].values\n",
        "\n",
        "# split the data in train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=10)\n",
        "\n",
        "# create the model with max_depth=3 (again) for rendering reasons\n",
        "model = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "\n",
        "# train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# import export_graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "# export files as stored as .dot files\n",
        "dot_file = export_graphviz(model, feature_names=feature_names,\n",
        "                           class_names= ['Not Diabetic', 'Diabetic'])\n",
        "\n",
        "# import graphviz to convert .dot file to a .png image\n",
        "import graphviz\n",
        "# read the dot_file\n",
        "graph = graphviz.Source(dot_file)\n",
        "# convert .dot to .png without generating additional files\n",
        "graph.render(filename='tree_diabetes', format='png', cleanup=True)\n",
        "\n",
        "# import IPython to display the rendered .png image\n",
        "from IPython.display import Image\n",
        "# display image using the path\n",
        "Image(filename=\"/content/tree_diabetes.png\")"
      ],
      "metadata": {
        "id": "pfa5t0ncFb2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='Pruning'> </a>\n",
        "# **Pruning the Decision Tree**\n",
        "Removing the unnecessary elements from the Decision Trees with the aim of:\n",
        "* Reducing the complexity to avoid overfitting\n",
        "* Making it easier to interpret.\n",
        "\n",
        "\n",
        "\n",
        "1. **Pre-Pruning**: the goal is to limit tree growth\n",
        "  * ***max_depth***: grow up to a certain depth/height\n",
        "  * ***min_samples_split***: the minimun number of samples required to split an internal node.\n",
        "  * ***max_leaf_nodes***: limit the total number of leaf nodes allowed in the tree\n",
        "\n",
        "    Additional info [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
        "\n",
        "2. **Post-pruning**: build the whole tree and then review the tree and decide which leaves to remove to make it smaller."
      ],
      "metadata": {
        "id": "5bRzoFg0d0tA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='Pre-Pruning'> </a>\n",
        "**Pre-Pruning** example:"
      ],
      "metadata": {
        "id": "LWCkXGFCft2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model with modified parameters\n",
        "model = DecisionTreeClassifier(criterion='entropy',\n",
        "                               max_depth=10,\n",
        "                               min_samples_split=4,\n",
        "                               max_leaf_nodes=20,)\n",
        "\n",
        "# train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# predict using the training data\n",
        "y_pred_train = model.predict(X_train)\n",
        "# predict using the test data\n",
        "y_pred = model.predict(X_test)\n",
        "# print accuracy\n",
        "print(\"Training Accuracy: {:.4f}\" .format(accuracy_score(y_train, y_pred_train)))\n",
        "print(\"Testing Accuracy: {:.4f}\" .format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "# import export_graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "# export files as stored as .dot files\n",
        "dot_file = export_graphviz(model, feature_names=feature_names,\n",
        "                           class_names= ['Not Diabetic', 'Diabetic'])\n",
        "\n",
        "# import graphviz to convert .dot file to a .png image\n",
        "import graphviz\n",
        "# read the dot_file\n",
        "graph = graphviz.Source(dot_file)\n",
        "# convert .dot to .png without generating additional files\n",
        "graph.render(filename='tree_diabetes', format='png', cleanup=True)\n",
        "\n",
        "# import IPython to display the rendered .png image\n",
        "from IPython.display import Image\n",
        "# display image using the path\n",
        "Image(filename=\"/content/tree_diabetes.png\")"
      ],
      "metadata": {
        "id": "M0-JfEcYdzEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Prunning successfully ***increased testing accuracy*** in comparison to the default model (77% vs. 73%)"
      ],
      "metadata": {
        "id": "dNI0lmZIklUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='Post-Pruning'> </a>\n",
        "**Post-Pruning** example:  \n",
        "(*the same tree as the default (first) model, recreated here with visualization*)"
      ],
      "metadata": {
        "id": "jmDHSRseg06c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model with modified parameters\n",
        "model = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "# train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# predict using the training data\n",
        "y_pred_train = model.predict(X_train)\n",
        "# predict using the test data\n",
        "y_pred = model.predict(X_test)\n",
        "# print accuracy\n",
        "print(\"Training Accuracy: {:.4f}\" .format(accuracy_score(y_train, y_pred_train)))\n",
        "print(\"Testing Accuracy: {:.4f}\" .format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "# import export_graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "# export files as stored as .dot files\n",
        "dot_file = export_graphviz(model, feature_names=feature_names,\n",
        "                           class_names= ['Not Diabetic', 'Diabetic'])\n",
        "\n",
        "# import graphviz to convert .dot file to a .png image\n",
        "import graphviz\n",
        "# read the dot_file\n",
        "graph = graphviz.Source(dot_file)\n",
        "# convert .dot to .png without generating additional files\n",
        "graph.render(filename='tree_diabetes', format='png', cleanup=True)\n",
        "\n",
        "# import IPython to display the rendered .png image\n",
        "from IPython.display import Image\n",
        "# display image using the path\n",
        "Image(filename=\"/content/tree_diabetes.png\")"
      ],
      "metadata": {
        "id": "2EH-cK_ng5_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Testing accuracy dropped considerably*** in comparison with the Pre-Prunned tree (0.74 vs. 0.77).  \n",
        "\n",
        "The full tree has now ***17 rows*** which results in an ***overfitting*** indication:  *the training accuracy score (100%) is much higher that the testing accuracy score (74%)*.\n",
        "\n",
        "Notice that, for example, in the ***7th row*** entropy scores are quite good, so try and stop tree growth there and see what happens."
      ],
      "metadata": {
        "id": "gQdkLSVehaOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model with modified parameters\n",
        "model = DecisionTreeClassifier(criterion='entropy',\n",
        "                               max_depth=7)\n",
        "\n",
        "# train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# predict using the training data\n",
        "y_pred_train = model.predict(X_train)\n",
        "# predict using the test data\n",
        "y_pred = model.predict(X_test)\n",
        "# print accuracy\n",
        "print(\"Training Accuracy: {:.4f}\" .format(accuracy_score(y_train, y_pred_train)))\n",
        "print(\"Testing Accuracy: {:.4f}\" .format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "# import export_graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "# export files as stored as .dot files\n",
        "dot_file = export_graphviz(model, feature_names=feature_names,\n",
        "                           class_names= ['Not Diabetic', 'Diabetic'])\n",
        "\n",
        "# import graphviz to convert .dot file to a .png image\n",
        "import graphviz\n",
        "# read the dot_file\n",
        "graph = graphviz.Source(dot_file)\n",
        "# convert .dot to .png without generating additional files\n",
        "graph.render(filename='tree_diabetes', format='png', cleanup=True)\n",
        "\n",
        "# import IPython to display the rendered .png image\n",
        "from IPython.display import Image\n",
        "# display image using the path\n",
        "Image(filename=\"/content/tree_diabetes.png\")"
      ],
      "metadata": {
        "id": "IqNfaseehaoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Testing accuracy score*** raised from ***73% to 76%*** with just the first modification."
      ],
      "metadata": {
        "id": "hmGL-WjbmTy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='Conclusions'> </a>\n",
        "# **Conclusions**\n",
        "1. **GraphViz** allows to easily generate a visual representation of the Decision Tree which greatly helps in its ***interpretability***!\n",
        "\n",
        "2. **Pre-Pruning** and **Post-Pruning** techniques were both successful to considerably ***increase testing accuracy*** and ***minimize overfitting*** with minimal modifications!"
      ],
      "metadata": {
        "id": "QaPtTye1nb-o"
      }
    }
  ]
}